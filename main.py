import cv2
import sqlite3
import time
import os
import threading
import pyttsx3
import easyocr
from ultralytics import YOLO

# --- Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ ---
YOLO_MODEL_PATH = "yolov8n.pt"  # Ù…Ø¯Ù„ YOLOv8
DB_PATH = "detections.db"       # Ø¯ÛŒØªØ§Ø¨ÛŒØ³
TEMP_IMAGE_PATH = "temp_frame.jpg"
TEMP_AUDIO_PATH = "temp_audio.mp3"

# --- Ø§ØªØµØ§Ù„ Ø¨Ù‡ Ø¯ÛŒØªØ§Ø¨ÛŒØ³ ---
conn = sqlite3.connect(DB_PATH)
cursor = conn.cursor()

cursor.execute('''
CREATE TABLE IF NOT EXISTS detections (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    label TEXT,
    confidence REAL,
    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP
)
''')
conn.commit()

# --- Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ YOLOv8 ---
model = YOLO(YOLO_MODEL_PATH)

# --- OCR Ùˆ TTS ---
reader = easyocr.Reader(['en'])  # ÙØ§Ø±Ø³ÛŒ Ø§Ú¯Ø± Ø¨Ø®ÙˆØ§ÛŒ Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†ÛŒ: ['fa','en']
engine = pyttsx3.init()

# --- Ù…Ø¯ÛŒØ±ÛŒØª Ø¢Ø®Ø±ÛŒÙ† Ø²Ù…Ø§Ù† Ø«Ø¨Øª Ø§Ø´ÛŒØ§ ---
last_seen = {}

# --- ÙˆØ¶Ø¹ÛŒØª Ø¨Ø±Ù†Ø§Ù…Ù‡ ---
processing_temp = False  # Ø¢ÛŒØ§ OCR+TTS Ø¯Ø± Ø­Ø§Ù„ Ø§Ø¬Ø±Ø§Ø³Øª
stop_audio_flag = False

def run_object_detection(frame):
    global last_seen
    results = model(frame)

    for r in results:
        boxes = r.boxes
        for box in boxes:
            cls = int(box.cls[0])
            label = model.names[cls]
            conf = float(box.conf[0])
            now = time.time()

            if label not in last_seen or (now - last_seen[label]) > 2:
                cursor.execute(
                    "INSERT INTO detections (label, confidence) VALUES (?, ?)",
                    (label, conf)
                )
                conn.commit()
                last_seen[label] = now
                print(f"Saved: {label} ({conf:.2f})")

    annotated_frame = results[0].plot()
    return annotated_frame

def text_to_speech(text):
    global stop_audio_flag
    stop_audio_flag = False
    engine.save_to_file(text, TEMP_AUDIO_PATH)
    engine.runAndWait()
    # Ù¾Ø®Ø´ ØµÙˆØª
    os.system(f'start /min wmplayer "{TEMP_AUDIO_PATH}"')  # Ø¨Ø±Ø§ÛŒ ÙˆÛŒÙ†Ø¯ÙˆØ²

def run_ocr_and_tts(image_path):
    global processing_temp
    img = cv2.imread(image_path)
    result = reader.readtext(img)
    text = " ".join([res[1] for res in result])
    if not text.strip():
        text = "âš ï¸ Ù…ØªÙ†ÛŒ Ø¨Ø±Ø§ÛŒ Ø®ÙˆØ§Ù†Ø¯Ù† Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯!"
    print(f"ğŸ“ Ù…ØªÙ† Ø§Ø³ØªØ®Ø±Ø§Ø¬â€ŒØ´Ø¯Ù‡:\n{text}\n")
    processing_temp = True
    text_to_speech(text)

def main():
    global processing_temp, stop_audio_flag
    cap = cv2.VideoCapture(0)
    temp_frame_saved = False

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        # ÙÙ‚Ø· ÙˆÙ‚ØªÛŒ Ú©Ù‡ OCR+TTS ÙØ¹Ø§Ù„ Ù†ÛŒØ³Øª â†’ YOLOv8 Ø§Ø¬Ø±Ø§ Ù…ÛŒØ´Ù‡
        if not processing_temp:
            annotated_frame = run_object_detection(frame)
        else:
            annotated_frame = frame.copy()

        cv2.imshow("YOLOv8 + OCR", annotated_frame)
        key = cv2.waitKey(1) & 0xFF

        if key == ord("q"):
            break
        elif key == ord(" "):  # Ø§Ø³Ù¾ÛŒØ³ â†’ Ø°Ø®ÛŒØ±Ù‡ ÙØ±ÛŒÙ… Ùˆ OCR
            if not processing_temp:
                cv2.imwrite(TEMP_IMAGE_PATH, frame)
                print("ğŸ“· Ø¹Ú©Ø³ Ú¯Ø±ÙØªÙ‡ Ø´Ø¯!")
                threading.Thread(target=run_ocr_and_tts, args=(TEMP_IMAGE_PATH,), daemon=True).start()
            else:
                # Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† ÙØ§ÛŒÙ„ Ù…ÙˆÙ‚Øª Ùˆ Ø§Ø¯Ø§Ù…Ù‡ YOLO
                if os.path.exists(TEMP_IMAGE_PATH):
                    os.remove(TEMP_IMAGE_PATH)
                if os.path.exists(TEMP_AUDIO_PATH):
                    os.remove(TEMP_AUDIO_PATH)
                print("ğŸ”„ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù…ÙˆÙ‚Øª Ø­Ø°Ù Ø´Ø¯Ù†Ø¯. Ù¾Ø±Ø¯Ø§Ø²Ø´ YOLO Ø§Ø¯Ø§Ù…Ù‡ Ø¯Ø§Ø±Ø¯.")
                processing_temp = False

    cap.release()
    conn.close()
    cv2.destroyAllWindows()

if __name__ == "__main__":
    main()
